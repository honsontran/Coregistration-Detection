{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "There is also a file named `requirements.txt`, which will install all dependencies required for training to work.\n",
    "\n",
    "Note: Mask-RCNN does **NOT** work with Tensorflow 2. This notebook has been run with:\n",
    "\n",
    "- Python 3.7\n",
    "- Tensorflow 1.15.0 (or tensorflow-gpu)\n",
    "- Keras 2.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out to reload imported modules if they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Comment out everything below if you are NOT using a GPU for training.\n",
    "# Feel free to change the config.gpu_options.per_process_gpu_memory_fraction to an appropriate percentage\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The directory can also be concatenated using `os.path.join()` in the event you don't want to mess with the `\\` convention for Windows and the universal `/` convention for every other OS. Also note that using `\\` in syntax requires you to write it out as `\\\\` because this indicates the insert of a special character (i.e `\\n` means new line).\n",
    "\n",
    "If you're on Windows, and you're using `os.path.join`, it's a good idea to leave the directory with a `\\\\` so that all the occurrences of `os.path.join()` will know that a `\\` convention is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\samples\\spine_segmented\\spine_segmented.py:28: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\samples\\spine_segmented\\spine_segmented.py:30: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = 'C:\\\\Users\\\\iFai1\\\\Desktop\\\\Cornell\\\\MRCNN_Iteration\\\\Mask_RCNN\\\\'\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "import samples.spine_segmented.spine_segmented as spine\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "There is another notebook that goes through training independent of inputting into the command line, such as the command below. That notebook in particular will give a better understanding of how training works.\n",
    "\n",
    "For simplicity in this notebook, we simply call the command below to launch training.\n",
    "\n",
    "## Reference of Commands\n",
    "For reference, this is a copy and paste of of training commands from the Mask-RCNN README:\n",
    "\n",
    "We're providing pre-trained weights for MS COCO to make it easier to start. You can\n",
    "use those weights as a starting point to train your own variation on the network.\n",
    "Training and evaluation code is in `samples/coco/coco.py`. You can import this\n",
    "module in Jupyter notebook (see the provided notebooks for examples) or you\n",
    "can run it directly from the command line as such:\n",
    "\n",
    "```\n",
    "# Train a new model starting from pre-trained COCO weights\n",
    "python3 samples/coco/coco.py train --dataset=/path/to/coco/ --model=coco\n",
    "\n",
    "# Train a new model starting from ImageNet weights\n",
    "python3 samples/coco/coco.py train --dataset=/path/to/coco/ --model=imagenet\n",
    "\n",
    "# Continue training a model that you had trained earlier\n",
    "python3 samples/coco/coco.py train --dataset=/path/to/coco/ --model=/path/to/weights.h5\n",
    "\n",
    "# Continue training the last model you trained. This will find\n",
    "# the last trained weights in the model directory.\n",
    "python3 samples/coco/coco.py train --dataset=/path/to/coco/ --model=last\n",
    "```\n",
    "\n",
    "You can also run the COCO evaluation code with:\n",
    "```\n",
    "# Run COCO evaluation on the last trained model\n",
    "python3 samples/coco/coco.py evaluate --dataset=/path/to/coco/ --model=last\n",
    "```\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "Here are some common problems I have came across when trying to get this to run on my computer. Refer to these if you're stuck.\n",
    "\n",
    "1. There's an error indicating directories weren't found, or some of the parameters (i.e --weights=\"coco\") are not valid.\n",
    "    - Check to make sure directory paths are valid. Also, Windows convention (not surprised) must use `\"` instead of `'` when inputting strings/parameters. For example, saying `--weights='coco'` on Windows will import it as `'coco'`, and Mask-RCNN is just checking for `coco`.\n",
    "    \n",
    "    \n",
    "2. `Resource exhausted: OOM when allocating tensor with shape[128,14,14,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc`\n",
    "    - There's not enough VRAM on your GPU. This could be of two causes. Check to see if you have other datasets/Jupyter notebooks loaded and running on your card. Be sure to shut them off. If you are still experiencing this problem, your `config.gpu_options.per_process_gpu_memory_fraction` config in the beginning of the notebook (when importing Tensorflow) might be set too high.\n",
    "    - Also, if you have ran this notebook multiple times, you should restart the kernel to clear any old datasets and imports that have been loaded onto the card. Then, run this again.\n",
    "\n",
    "3. `ValueError: need at least one array to stack`\n",
    "    - This is most likely caused by an image that doesn't have **at least** one mask for the image. Causing an error. Make sure to clean up your dataset if that is the case! There should be some scripts in `/data_utils` that I have created that will do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  coco\n",
      "Dataset:  C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\datasets\\spine_segmented\n",
      "Subset:  train\n",
      "Logs:  C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\logs\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        400\n",
      "DETECTION_MIN_CONFIDENCE       0\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                2.0\n",
      "IMAGE_RESIZE_MODE              crop\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               200\n",
      "MEAN_PIXEL                     [43.53 39.56 48.22]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           spine\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        2000\n",
      "POST_NMS_ROIS_TRAINING         1000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.9\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    64\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           128\n",
      "USE_MINI_MASK                  False\n",
      "USE_RPN_ROIS                   True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-07 17:42:12.168427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n",
      "WARNING:tensorflow:From C:/Users/iFai1/Desktop/Cornell/MRCNN_Iteration/Mask_RCNN/samples/spine_segmented/spine_segmented.py:28: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:/Users/iFai1/Desktop/Cornell/MRCNN_Iteration/Mask_RCNN/samples/spine_segmented/spine_segmented.py:30: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2020-06-07 17:42:13.243403: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
      "2020-06-07 17:42:13.246074: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\n",
      "2020-06-07 17:42:13.265871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2070 with Max-Q Design major: 7 minor: 5 memoryClockRate(GHz): 1.185\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-06-07 17:42:13.266077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n",
      "2020-06-07 17:42:13.268032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll\n",
      "2020-06-07 17:42:13.269793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll\n",
      "2020-06-07 17:42:13.270575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll\n",
      "2020-06-07 17:42:13.273024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll\n",
      "2020-06-07 17:42:13.274784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll\n",
      "2020-06-07 17:42:13.279248: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\n",
      "2020-06-07 17:42:13.279683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-06-07 17:42:13.797152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-06-07 17:42:13.797294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2020-06-07 17:42:13.797411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2020-06-07 17:42:13.798150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6306 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2020-06-07 17:42:13.800741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2070 with Max-Q Design major: 7 minor: 5 memoryClockRate(GHz): 1.185\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-06-07 17:42:13.800946: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n",
      "2020-06-07 17:42:13.801065: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll\n",
      "2020-06-07 17:42:13.801205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll\n",
      "2020-06-07 17:42:13.801285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll\n",
      "2020-06-07 17:42:13.801365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll\n",
      "2020-06-07 17:42:13.801521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll\n",
      "2020-06-07 17:42:13.801658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\n",
      "2020-06-07 17:42:13.802017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-06-07 17:42:13.802160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-06-07 17:42:13.802290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2020-06-07 17:42:13.802371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2020-06-07 17:42:13.802699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6306 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2020-06-07 17:42:18.052013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2070 with Max-Q Design major: 7 minor: 5 memoryClockRate(GHz): 1.185\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-06-07 17:42:18.052213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n",
      "2020-06-07 17:42:18.052356: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll\n",
      "2020-06-07 17:42:18.052492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll\n",
      "2020-06-07 17:42:18.052620: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll\n",
      "2020-06-07 17:42:18.052746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll\n",
      "2020-06-07 17:42:18.052950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll\n",
      "2020-06-07 17:42:18.053092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\n",
      "2020-06-07 17:42:18.053439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-06-07 17:42:18.053574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-06-07 17:42:18.053697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2020-06-07 17:42:18.053769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2020-06-07 17:42:18.054060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6306 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "2020-06-07 17:42:28.337375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll\n",
      "2020-06-07 17:42:28.605693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\n",
      "2020-06-07 17:42:29.763126: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Internal: Invoking ptxas not supported on Windows\n",
      "Relying on driver to perform ptx compilation. This message will be only logged once.\n",
      "ERROR:root:Error processing image {'id': 'P00190261.tif', 'source': 'spine', 'path': 'C:\\\\Users\\\\iFai1\\\\Desktop\\\\Cornell\\\\MRCNN_Iteration\\\\Mask_RCNN\\\\datasets\\\\spine_segmented\\\\data\\\\train\\\\img\\\\P00190261.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\", line 1711, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
      "    mask, class_ids = dataset.load_mask(image_id)\n",
      "  File \"C:/Users/iFai1/Desktop/Cornell/MRCNN_Iteration/Mask_RCNN/samples/spine_segmented/spine_segmented.py\", line 241, in load_mask\n",
      "    mask = np.stack(mask, axis=-1)\n",
      "  File \"<__array_function__ internals>\", line 6, in stack\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\numpy\\core\\shape_base.py\", line 422, in stack\n",
      "    raise ValueError('need at least one array to stack')\n",
      "ValueError: need at least one array to stack\n",
      "ERROR:root:Error processing image {'id': 'P00200155.tif', 'source': 'spine', 'path': 'C:\\\\Users\\\\iFai1\\\\Desktop\\\\Cornell\\\\MRCNN_Iteration\\\\Mask_RCNN\\\\datasets\\\\spine_segmented\\\\data\\\\train\\\\img\\\\P00200155.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\", line 1711, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
      "    mask, class_ids = dataset.load_mask(image_id)\n",
      "  File \"C:/Users/iFai1/Desktop/Cornell/MRCNN_Iteration/Mask_RCNN/samples/spine_segmented/spine_segmented.py\", line 241, in load_mask\n",
      "    mask = np.stack(mask, axis=-1)\n",
      "  File \"<__array_function__ internals>\", line 6, in stack\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\numpy\\core\\shape_base.py\", line 422, in stack\n",
      "    raise ValueError('need at least one array to stack')\n",
      "ValueError: need at least one array to stack\n",
      "ERROR:root:Error processing image {'id': 'P00190125.tif', 'source': 'spine', 'path': 'C:\\\\Users\\\\iFai1\\\\Desktop\\\\Cornell\\\\MRCNN_Iteration\\\\Mask_RCNN\\\\datasets\\\\spine_segmented\\\\data\\\\train\\\\img\\\\P00190125.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\", line 1711, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
      "    mask, class_ids = dataset.load_mask(image_id)\n",
      "  File \"C:/Users/iFai1/Desktop/Cornell/MRCNN_Iteration/Mask_RCNN/samples/spine_segmented/spine_segmented.py\", line 241, in load_mask\n",
      "    mask = np.stack(mask, axis=-1)\n",
      "  File \"<__array_function__ internals>\", line 6, in stack\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\numpy\\core\\shape_base.py\", line 422, in stack\n",
      "    raise ValueError('need at least one array to stack')\n",
      "ValueError: need at least one array to stack\n",
      "ERROR:root:Error processing image {'id': 'P00200282.tif', 'source': 'spine', 'path': 'C:\\\\Users\\\\iFai1\\\\Desktop\\\\Cornell\\\\MRCNN_Iteration\\\\Mask_RCNN\\\\datasets\\\\spine_segmented\\\\data\\\\train\\\\img\\\\P00200282.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\", line 1711, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
      "    mask, class_ids = dataset.load_mask(image_id)\n",
      "  File \"C:/Users/iFai1/Desktop/Cornell/MRCNN_Iteration/Mask_RCNN/samples/spine_segmented/spine_segmented.py\", line 241, in load_mask\n",
      "    mask = np.stack(mask, axis=-1)\n",
      "  File \"<__array_function__ internals>\", line 6, in stack\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\numpy\\core\\shape_base.py\", line 422, in stack\n",
      "    raise ValueError('need at least one array to stack')\n",
      "ValueError: need at least one array to stack\n",
      "ERROR:root:Error processing image {'id': 'P00180319.tif', 'source': 'spine', 'path': 'C:\\\\Users\\\\iFai1\\\\Desktop\\\\Cornell\\\\MRCNN_Iteration\\\\Mask_RCNN\\\\datasets\\\\spine_segmented\\\\data\\\\train\\\\img\\\\P00180319.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\", line 1711, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
      "    mask, class_ids = dataset.load_mask(image_id)\n",
      "  File \"C:/Users/iFai1/Desktop/Cornell/MRCNN_Iteration/Mask_RCNN/samples/spine_segmented/spine_segmented.py\", line 241, in load_mask\n",
      "    mask = np.stack(mask, axis=-1)\n",
      "  File \"<__array_function__ internals>\", line 6, in stack\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\numpy\\core\\shape_base.py\", line 422, in stack\n",
      "    raise ValueError('need at least one array to stack')\n",
      "ValueError: need at least one array to stack\n",
      "ERROR:root:Error processing image {'id': 'P00220144.tif', 'source': 'spine', 'path': 'C:\\\\Users\\\\iFai1\\\\Desktop\\\\Cornell\\\\MRCNN_Iteration\\\\Mask_RCNN\\\\datasets\\\\spine_segmented\\\\data\\\\train\\\\img\\\\P00220144.tif'}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\", line 1711, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
      "    mask, class_ids = dataset.load_mask(image_id)\n",
      "  File \"C:/Users/iFai1/Desktop/Cornell/MRCNN_Iteration/Mask_RCNN/samples/spine_segmented/spine_segmented.py\", line 241, in load_mask\n",
      "    mask = np.stack(mask, axis=-1)\n",
      "  File \"<__array_function__ internals>\", line 6, in stack\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\numpy\\core\\shape_base.py\", line 422, in stack\n",
      "    raise ValueError('need at least one array to stack')"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Loading weights  C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mask_rcnn_coco.h5\n",
      "Train network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\logs\\spine20200607T1742\\mask_rcnn_spine_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/20\n",
      "\n",
      "  1/100 [..............................] - ETA: 15:56 - loss: 8.6629 - rpn_class_loss: 0.1163 - rpn_bbox_loss: 3.8359 - mrcnn_class_loss: 1.7196 - mrcnn_bbox_loss: 2.2590 - mrcnn_mask_loss: 0.7321\n",
      "  2/100 [..............................] - ETA: 8:13 - loss: 6.6993 - rpn_class_loss: 0.1938 - rpn_bbox_loss: 3.6307 - mrcnn_class_loss: 1.3793 - mrcnn_bbox_loss: 1.1295 - mrcnn_mask_loss: 0.3660 \n",
      "  3/100 [..............................] - ETA: 5:38 - loss: 6.6582 - rpn_class_loss: 0.3997 - rpn_bbox_loss: 3.6406 - mrcnn_class_loss: 1.0354 - mrcnn_bbox_loss: 0.9900 - mrcnn_mask_loss: 0.5925\n",
      "  4/100 [>.............................] - ETA: 4:20 - loss: 5.6894 - rpn_class_loss: 0.3227 - rpn_bbox_loss: 2.8487 - mrcnn_class_loss: 0.8343 - mrcnn_bbox_loss: 1.0481 - mrcnn_mask_loss: 0.6356\n",
      "  5/100 [>.............................] - ETA: 3:34 - loss: 6.0123 - rpn_class_loss: 0.3346 - rpn_bbox_loss: 3.0059 - mrcnn_class_loss: 0.9112 - mrcnn_bbox_loss: 1.0610 - mrcnn_mask_loss: 0.6996\n",
      "  6/100 [>.............................] - ETA: 3:03 - loss: 6.2242 - rpn_class_loss: 0.5258 - rpn_bbox_loss: 3.0948 - mrcnn_class_loss: 0.7919 - mrcnn_bbox_loss: 1.0979 - mrcnn_mask_loss: 0.7137\n",
      "  7/100 [=>............................] - ETA: 2:40 - loss: 6.4799 - rpn_class_loss: 0.4840 - rpn_bbox_loss: 3.4777 - mrcnn_class_loss: 0.6861 - mrcnn_bbox_loss: 1.1020 - mrcnn_mask_loss: 0.7301\n",
      "  8/100 [=>............................] - ETA: 2:23 - loss: 6.5133 - rpn_class_loss: 0.4906 - rpn_bbox_loss: 3.4596 - mrcnn_class_loss: 0.6037 - mrcnn_bbox_loss: 1.2302 - mrcnn_mask_loss: 0.7292\n",
      "  9/100 [=>............................] - ETA: 2:10 - loss: 7.0674 - rpn_class_loss: 0.7448 - rpn_bbox_loss: 3.7712 - mrcnn_class_loss: 0.5767 - mrcnn_bbox_loss: 1.1820 - mrcnn_mask_loss: 0.7927\n",
      " 10/100 [==>...........................] - ETA: 1:59 - loss: 6.5667 - rpn_class_loss: 0.6762 - rpn_bbox_loss: 3.5942 - mrcnn_class_loss: 0.5190 - mrcnn_bbox_loss: 1.0638 - mrcnn_mask_loss: 0.7135\n",
      " 11/100 [==>...........................] - ETA: 1:51 - loss: 6.4110 - rpn_class_loss: 0.6741 - rpn_bbox_loss: 3.4425 - mrcnn_class_loss: 0.5019 - mrcnn_bbox_loss: 1.0691 - mrcnn_mask_loss: 0.7236\n",
      " 12/100 [==>...........................] - ETA: 1:43 - loss: 6.2317 - rpn_class_loss: 0.6256 - rpn_bbox_loss: 3.5028 - mrcnn_class_loss: 0.4600 - mrcnn_bbox_loss: 0.9800 - mrcnn_mask_loss: 0.6633\n",
      " 13/100 [==>...........................] - ETA: 1:37 - loss: 6.1222 - rpn_class_loss: 0.5962 - rpn_bbox_loss: 3.4588 - mrcnn_class_loss: 0.4487 - mrcnn_bbox_loss: 0.9504 - mrcnn_mask_loss: 0.6679\n",
      " 14/100 [===>..........................] - ETA: 1:31 - loss: 6.0570 - rpn_class_loss: 0.5768 - rpn_bbox_loss: 3.5607 - mrcnn_class_loss: 0.4167 - mrcnn_bbox_loss: 0.8825 - mrcnn_mask_loss: 0.6202\n",
      " 15/100 [===>..........................] - ETA: 1:27 - loss: 6.0862 - rpn_class_loss: 0.6073 - rpn_bbox_loss: 3.4968 - mrcnn_class_loss: 0.4023 - mrcnn_bbox_loss: 0.9517 - mrcnn_mask_loss: 0.6281\n",
      " 16/100 [===>..........................] - ETA: 1:22 - loss: 5.9242 - rpn_class_loss: 0.5744 - rpn_bbox_loss: 3.3683 - mrcnn_class_loss: 0.3997 - mrcnn_bbox_loss: 0.9485 - mrcnn_mask_loss: 0.6334\n",
      " 17/100 [====>.........................] - ETA: 1:18 - loss: 5.8534 - rpn_class_loss: 0.5714 - rpn_bbox_loss: 3.4170 - mrcnn_class_loss: 0.3762 - mrcnn_bbox_loss: 0.8927 - mrcnn_mask_loss: 0.5961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ValueError: need at least one array to stack\n",
      "Traceback (most recent call last):\n",
      "  File \"C:/Users/iFai1/Desktop/Cornell/MRCNN_Iteration/Mask_RCNN/samples/spine_segmented/spine_segmented.py\", line 490, in <module>\n",
      "    train(model, args.dataset, args.subset)\n",
      "  File \"C:/Users/iFai1/Desktop/Cornell/MRCNN_Iteration/Mask_RCNN/samples/spine_segmented/spine_segmented.py\", line 291, in train\n",
      "    layers='heads')\n",
      "  File \"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\", line 2376, in train\n",
      "    use_multiprocessing=True,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\engine\\training.py\", line 1658, in fit_generator\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\engine\\training_generator.py\", line 181, in fit_generator\n",
      "    generator_output = next(output_generator)\n",
      "  File \"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\", line 1711, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
      "    mask, class_ids = dataset.load_mask(image_id)\n",
      "  File \"C:/Users/iFai1/Desktop/Cornell/MRCNN_Iteration/Mask_RCNN/samples/spine_segmented/spine_segmented.py\", line 241, in load_mask\n",
      "    mask = np.stack(mask, axis=-1)\n",
      "  File \"<__array_function__ internals>\", line 6, in stack\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\numpy\\core\\shape_base.py\", line 422, in stack\n",
      "    raise ValueError('need at least one array to stack')\n",
      "ValueError: need at least one array to stack\n"
     ]
    }
   ],
   "source": [
    "!python C:/Users/iFai1/Desktop/Cornell/MRCNN_Iteration/Mask_RCNN/samples/spine_segmented/spine_segmented.py train --dataset=\"C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\datasets\\spine_segmented\" --subset=train --weights=\"coco\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup our model for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is just some prelimnary formatting to display images on the notebook. Change as you see fit for the image to be displayed in this notebook. This does not interfere with anything pertaining to our training/model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following to check out parameters of the model for double checking and reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        400\n",
      "DETECTION_MIN_CONFIDENCE       0\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                2.0\n",
      "IMAGE_RESIZE_MODE              pad64\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               200\n",
      "MEAN_PIXEL                     [43.53 39.56 48.22]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           spine\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        2000\n",
      "POST_NMS_ROIS_TRAINING         1000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    64\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           128\n",
      "USE_MINI_MASK                  False\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset directory\n",
    "DATASET_DIR = os.path.join(ROOT_DIR, \"datasets/spine_segmented\")\n",
    "\n",
    "# Inference Configuration\n",
    "config = spine.SpineInferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 1910\n",
      "Classes: ['BG', 'v1', 'v2', 'v3']\n"
     ]
    }
   ],
   "source": [
    "# Load validation dataset\n",
    "dataset = spine.SpineDataset()\n",
    "dataset.load_spine(DATASET_DIR, \"train\") # train is selected here on purpose to test on train set first\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model & weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# Only inference mode is supported right now\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py:758: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py:760: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=TEST_MODE,\n",
    "                              model_dir=LOGS_DIR,\n",
    "                              config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights  C:\\Users\\iFai1\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\logs\\spine20200607T1545\\mask_rcnn_spine_0001.h5\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (bad object header version number)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f4c90d27d418>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Load weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loading weights \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m# model.load_weights(weights_path, by_name=True, exclude=[ \"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Cornell\\MRCNN_Iteration\\Mask_RCNN\\mrcnn\\model.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[0;32m   2115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2116\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`load_weights` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2117\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cornell-mrcnn\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (bad object header version number)"
     ]
    }
   ],
   "source": [
    "# Path to a specific weights file\n",
    "# weights_path = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Or, load the last model you trained\n",
    "weights_path = model.find_last()\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "# model.load_weights(weights_path, by_name=True, exclude=[ \"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "\n",
    "If you are experiencing errors with this, such as the `ValueError: need at least one array to stack` error, the image chosen might not have detected anything at all, causing this error.\n",
    "\n",
    "To insert more images and their ground truths for testing, place them into `MaskRCNN/datasets/spine_segmented/data/val` and place them either in `/img` or `/gt` whether they're the physical image or the ground truth.\n",
    "\n",
    "You can rerun this again to receive another image. If there is a particular image you wish you see, simply edit `image_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_id = random.choice(dataset.image_ids)\n",
    "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
    "info = dataset.image_info[image_id]\n",
    "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
    "                                       dataset.image_reference(image_id)))\n",
    "print(\"Original image shape: \", modellib.parse_image_meta(image_meta[np.newaxis,...])[\"original_image_shape\"][0])\n",
    "\n",
    "# Run object detection\n",
    "results = model.detect_molded(np.expand_dims(image, 0), np.expand_dims(image_meta, 0), verbose=1)\n",
    "\n",
    "# Display results\n",
    "r = results[0]\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "# Compute AP over range 0.5 to 0.95 and print it\n",
    "utils.compute_ap_range(gt_bbox, gt_class_id, gt_mask,\n",
    "                       r['rois'], r['class_ids'], r['scores'], r['masks'],\n",
    "                       verbose=1)\n",
    "\n",
    "visualize.display_differences(\n",
    "    image,\n",
    "    gt_bbox, gt_class_id, gt_mask,\n",
    "    r['rois'], r['class_ids'], r['scores'], r['masks'],\n",
    "    dataset.class_names, ax=get_ax(),\n",
    "    show_box=False, show_mask=False,\n",
    "    iou_threshold=0.5, score_threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('cornell-mrcnn': conda)",
   "language": "python",
   "name": "python37764bitcornellmrcnnconda43d28c960bd94d25b60921a2c485453a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
